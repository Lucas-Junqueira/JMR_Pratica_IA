{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228ab748",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(zip_url)\n\u001b[0;32m     48\u001b[0m zip_bytes \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m archive:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Dicionário {nome_arquivo: bytes}\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     images_dict \u001b[38;5;241m=\u001b[39m {name: archive\u001b[38;5;241m.\u001b[39mread(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m archive\u001b[38;5;241m.\u001b[39mnamelist() \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m))}\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# --- Dataset customizado ---\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\zipfile.py:1313\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1315\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\zipfile.py:1380\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "import io\n",
    "import requests\n",
    "import zipfile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomOxfordDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_file, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.annotations.iloc[idx, 0]\n",
    "        label = int(self.annotations.iloc[idx, 1])\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# --- URLs raw do GitHub ---\n",
    "zip_url = \"https://github.com/Lucas-Junqueira/Pratica_IA/raw/main/oxford_subset/images_zip.zip\"\n",
    "csv_url = \"https://github.com/Lucas-Junqueira/Pratica_IA/raw/main/oxford_subset/labels/labels.csv\"\n",
    "\n",
    "# --- Ler CSV diretamente ---\n",
    "labels_df = pd.read_csv(csv_url)\n",
    "\n",
    "# --- Baixar ZIP e carregar imagens em memória ---\n",
    "import requests\n",
    "response = requests.get(zip_url)\n",
    "zip_bytes = io.BytesIO(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_bytes, 'r') as archive:\n",
    "    # Dicionário {nome_arquivo: bytes}\n",
    "    images_dict = {name: archive.read(name) for name in archive.namelist() if name.lower().endswith(('.jpg', '.png'))}\n",
    "\n",
    "# --- Dataset customizado ---\n",
    "class InMemoryZipDataset(Dataset):\n",
    "    def __init__(self, images_dict, labels_df, transform=None):\n",
    "        self.images_dict = images_dict\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_name = row[\"filename\"]\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        # Abrir imagem direto dos bytes\n",
    "        image = Image.open(io.BytesIO(self.images_dict[img_name])).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- Transformações ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- Dataset e DataLoader ---\n",
    "dataset = InMemoryZipDataset(images_dict, labels_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# --- Modelo ResNet50 pré-treinado ---\n",
    "model = resnet50(weights=\"IMAGENET1K_V1\")\n",
    "model.eval()\n",
    "\n",
    "# --- Captura dos feature maps ---\n",
    "feature_maps = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        feature_maps[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.layer1.register_forward_hook(get_activation('layer1'))\n",
    "model.layer2.register_forward_hook(get_activation('layer2'))\n",
    "model.layer3.register_forward_hook(get_activation('layer3'))\n",
    "model.layer4.register_forward_hook(get_activation('layer4'))\n",
    "\n",
    "# --- Funções auxiliares ---\n",
    "def show_image(img, ax=None):\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    if ax is None:\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "def show_feature_map(fmap, num_channels=4):\n",
    "    fmap = fmap.squeeze(0)  # remove batch\n",
    "    channels = torch.linspace(0, fmap.shape[0]-1, steps=num_channels).long()\n",
    "    fig, axes = plt.subplots(1, num_channels, figsize=(12, 4))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(fmap[channels[i]].cpu().numpy(), cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Grad-CAM ---\n",
    "gradients = {}\n",
    "activations = {}\n",
    "def forward_hook(module, input, output):\n",
    "    activations[\"value\"] = output.detach()\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients[\"value\"] = grad_out[0].detach()\n",
    "\n",
    "target_layer = model.layer4[-1]\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "def generate_gradcam(image_tensor, class_idx=None):\n",
    "    output = model(image_tensor)\n",
    "    if class_idx is None:\n",
    "        class_idx = output.argmax(dim=1).item()\n",
    "    model.zero_grad()\n",
    "    loss = output[0, class_idx]\n",
    "    loss.backward()\n",
    "    grads = gradients[\"value\"]\n",
    "    acts = activations[\"value\"]\n",
    "    weights = grads.mean(dim=(2, 3), keepdim=True)\n",
    "    cam = (weights * acts).sum(dim=1).squeeze()\n",
    "    cam = F.relu(cam)\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "    return cam.cpu().numpy()\n",
    "\n",
    "def show_gradcam_on_image(img_tensor, cam, ax, alpha=0.5):\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    cam_tensor = torch.tensor(cam).unsqueeze(0).unsqueeze(0)\n",
    "    cam_resized = F.interpolate(cam_tensor, size=(img.shape[0], img.shape[1]), mode='bilinear', align_corners=False)\n",
    "    cam_resized = cam_resized.squeeze().numpy()\n",
    "    heatmap = plt.cm.jet(cam_resized)[..., :3]\n",
    "    overlay = heatmap * alpha + img * (1 - alpha)\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    ax.imshow(overlay)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# --- Processar imagens do subset salvo ---\n",
    "for idx, (image, label) in enumerate(dataloader):\n",
    "    feature_maps.clear()\n",
    "    _ = model(image)  # forward\n",
    "\n",
    "    print(f\"\\n=== Imagem {idx+1} ===\")\n",
    "\n",
    "    cam = generate_gradcam(image)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    show_image(image[0], axes[0])\n",
    "    axes[0].set_title(\"Imagem Original\")\n",
    "    show_gradcam_on_image(image[0], cam, axes[1])\n",
    "    axes[1].set_title(\"Grad-CAM (layer4)\")\n",
    "    plt.show()\n",
    "\n",
    "    for name, fmap in feature_maps.items():\n",
    "        print(f\"Feature map - {name}:\")\n",
    "        show_feature_map(fmap, num_channels=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP2_ICV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
