{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228ab748",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x000001F2C06A20C0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 158\u001b[0m\n\u001b[0;32m    155\u001b[0m     ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# --- Processar imagens do subset salvo ---\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_maps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# forward\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 64\u001b[0m, in \u001b[0;36mGitHubDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Baixar imagem direto da URL\u001b[39;00m\n\u001b[0;32m     63\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(img_url)\n\u001b[1;32m---> 64\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     67\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\envs\\TP2_ICV\\Lib\\site-packages\\PIL\\Image.py:3536\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3534\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3535\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3536\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x000001F2C06A20C0>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "import io\n",
    "import requests\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomOxfordDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_file, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.annotations.iloc[idx, 0]\n",
    "        label = int(self.annotations.iloc[idx, 1])\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# --- Path do Dataset ---\n",
    "base_url = \"https://github.com/Lucas-Junqueira/Pratica_IA/tree/main/oxford_subset\"\n",
    "csv_url = \"https://raw.githubusercontent.com/Lucas-Junqueira/Pratica_IA/refs/heads/main/oxford_subset/labels.csv\"\n",
    "\n",
    "# --- Baixar CSV ---\n",
    "labels_df = pd.read_csv(csv_url)\n",
    "\n",
    "# --- Dataset em memória ---\n",
    "class GitHubDataset(Dataset):\n",
    "    def __init__(self, base_url, labels_df, transform=None):\n",
    "        self.base_url = base_url\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_name = row[\"filename\"]   # coluna do CSV com nome do arquivo\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        # Montar URL da imagem\n",
    "        img_url = self.base_url + img_name\n",
    "\n",
    "        # Baixar imagem direto da URL\n",
    "        response = requests.get(img_url)\n",
    "        image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- Transformações ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- Criar dataset ---\n",
    "dataset = GitHubDataset(base_url, labels_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# --- Modelo ResNet50 pré-treinado ---\n",
    "model = resnet50(weights=\"IMAGENET1K_V1\")\n",
    "model.eval()\n",
    "\n",
    "# --- Captura dos feature maps ---\n",
    "feature_maps = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        feature_maps[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.layer1.register_forward_hook(get_activation('layer1'))\n",
    "model.layer2.register_forward_hook(get_activation('layer2'))\n",
    "model.layer3.register_forward_hook(get_activation('layer3'))\n",
    "model.layer4.register_forward_hook(get_activation('layer4'))\n",
    "\n",
    "# --- Funções auxiliares ---\n",
    "def show_image(img, ax=None):\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    if ax is None:\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "def show_feature_map(fmap, num_channels=4):\n",
    "    fmap = fmap.squeeze(0)  # remove batch\n",
    "    channels = torch.linspace(0, fmap.shape[0]-1, steps=num_channels).long()\n",
    "    fig, axes = plt.subplots(1, num_channels, figsize=(12, 4))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(fmap[channels[i]].cpu().numpy(), cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Grad-CAM ---\n",
    "gradients = {}\n",
    "activations = {}\n",
    "def forward_hook(module, input, output):\n",
    "    activations[\"value\"] = output.detach()\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients[\"value\"] = grad_out[0].detach()\n",
    "\n",
    "target_layer = model.layer4[-1]\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "def generate_gradcam(image_tensor, class_idx=None):\n",
    "    output = model(image_tensor)\n",
    "    if class_idx is None:\n",
    "        class_idx = output.argmax(dim=1).item()\n",
    "    model.zero_grad()\n",
    "    loss = output[0, class_idx]\n",
    "    loss.backward()\n",
    "    grads = gradients[\"value\"]\n",
    "    acts = activations[\"value\"]\n",
    "    weights = grads.mean(dim=(2, 3), keepdim=True)\n",
    "    cam = (weights * acts).sum(dim=1).squeeze()\n",
    "    cam = F.relu(cam)\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "    return cam.cpu().numpy()\n",
    "\n",
    "def show_gradcam_on_image(img_tensor, cam, ax, alpha=0.5):\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    cam_tensor = torch.tensor(cam).unsqueeze(0).unsqueeze(0)\n",
    "    cam_resized = F.interpolate(cam_tensor, size=(img.shape[0], img.shape[1]), mode='bilinear', align_corners=False)\n",
    "    cam_resized = cam_resized.squeeze().numpy()\n",
    "    heatmap = plt.cm.jet(cam_resized)[..., :3]\n",
    "    overlay = heatmap * alpha + img * (1 - alpha)\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    ax.imshow(overlay)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# --- Processar imagens do subset salvo ---\n",
    "for idx, (image, label) in enumerate(dataloader):\n",
    "    feature_maps.clear()\n",
    "    _ = model(image)  # forward\n",
    "\n",
    "    print(f\"\\n=== Imagem {idx+1} ===\")\n",
    "\n",
    "    cam = generate_gradcam(image)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    show_image(image[0], axes[0])\n",
    "    axes[0].set_title(\"Imagem Original\")\n",
    "    show_gradcam_on_image(image[0], cam, axes[1])\n",
    "    axes[1].set_title(\"Grad-CAM (layer4)\")\n",
    "    plt.show()\n",
    "\n",
    "    for name, fmap in feature_maps.items():\n",
    "        print(f\"Feature map - {name}:\")\n",
    "        show_feature_map(fmap, num_channels=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP2_ICV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
